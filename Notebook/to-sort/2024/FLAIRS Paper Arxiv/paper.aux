\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{kisby2022logic}
\citation{tensorflow2015-whitepaper}
\citation{valiant2003three}
\citation{bader2005dimensions}
\citation{sarker2021neuro}
\citation{balkenius1991nonmonotonic}
\citation{leitgeb2001nonmonotonic,leitgeb2003nonmonotonic}
\citation{leitgeb2001nonmonotonic}
\@writefile{toc}{\contentsline {section}{Introduction}{1}{section*.1}\protected@file@percent }
\citation{mcculloch1943logical}
\citation{balkenius1991nonmonotonic}
\citation{leitgeb2001nonmonotonic,leitgeb2003nonmonotonic,leitgeb2018neural}
\citation{blutner2004nonmonotonic}
\citation{giordano2021}
\citation{garcez2001symbolic}
\citation{garcez2008neural}
\citation{baltag2019dynamic}
\citation{baltag2019right}
\citation{van2007prefupgrade}
\citation{van2007beliefrevision}
\@writefile{toc}{\contentsline {section}{Related Work}{2}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Logics with Neural Semantics.}{2}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Neuro-Symbolic AI.}{2}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Dynamic Logics for Learning.}{2}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Background}{2}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Neural Network Models}{2}{section*.7}\protected@file@percent }
\citation{leitgeb2001nonmonotonic}
\citation{leitgeb2001nonmonotonic}
\citation{leitgeb2001nonmonotonic}
\citation{leitgeb2001nonmonotonic}
\@writefile{toc}{\contentsline {subsection}{The Dynamics of Propagation}{3}{section*.8}\protected@file@percent }
\newlabel{thm:prop-props}{{1}{3}{}{theorem.0.1}{}}
\citation{kraus1990nonmonotonic}
\citation{hebb-organization-of-behavior-1949}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces (Left) The BFNN $\mathcal  {N}_1$ illustrates how BFNNs leverage negative weights to perform nonmonotonic inferences. (Right) TODO }}{4}{figure.1}\protected@file@percent }
\newlabel{fig:monotonicity-counterexamples}{{1}{4}{(Left) The BFNN $\Net _1$ illustrates how BFNNs leverage negative weights to perform nonmonotonic inferences. (Right) TODO}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{From Hebbian Learning to Logic}{4}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{The Dynamics of Hebbian Learning}{4}{section*.10}\protected@file@percent }
\newlabel{def:inc}{{4}{5}{}{definition.4}{}}
\newlabel{thm:inc-props}{{2}{5}{}{theorem.0.2}{}}
\citation{leitgeb2001nonmonotonic}
\citation{leitgeb2001nonmonotonic}
\citation{giordano2021}
\citation{van2007prefupgrade}
\citation{leitgeb2001nonmonotonic}
\@writefile{toc}{\contentsline {subsection}{Syntax and Semantics}{7}{section*.11}\protected@file@percent }
\citation{kisby2022logic}
\@writefile{toc}{\contentsline {subsection}{Inference and Axioms}{8}{section*.12}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A list of sound rules and axioms of the logic of Hebbian learning. We leave the question of completeness to future work.}}{8}{figure.2}\protected@file@percent }
\newlabel{fig:proof-system}{{2}{8}{A list of sound rules and axioms of the logic of Hebbian learning. We leave the question of completeness to future work}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A BFNN $\mathcal  {N}$, equipped with the ReLU activation function, $T = 1$, and $\eta = 1$. After observing the dataset $\langle \textrm  {orca}, \textrm  {zebra}, \textrm  {panda} \rangle $, $\mathcal  {N}$ learns that penguins do not fly, while preserving the fact that birds typically fly. \leavevmode {\color  {myred}TODO}}}{9}{figure.3}\protected@file@percent }
\newlabel{fig:full-example}{{3}{9}{A BFNN $\Net $, equipped with the ReLU activation function, $T = 1$, and $\eta = 1$. After observing the dataset $\langle \textrm {orca}, \textrm {zebra}, \textrm {panda} \rangle $, $\Net $ learns that penguins do not fly, while preserving the fact that birds typically fly. \textcolor {myred}{TODO}}{figure.3}{}}
\@writefile{toc}{\contentsline {section}{Applying the Logic: A Concrete Example}{9}{section*.13}\protected@file@percent }
\newlabel{sec:concrete}{{}{9}{Applying the Logic: A Concrete Example}{section*.13}{}}
\@writefile{toc}{\contentsline {section}{Conclusion and Future Work}{9}{section*.14}\protected@file@percent }
\bibstyle{plainnat}
\bibdata{neurosymbolic}
\bibcite{tensorflow2015-whitepaper}{{1}{2015}{{Abadi et~al.}}{{}}}
\bibcite{bader2005dimensions}{{2}{2005}{{Bader and Hitzler}}{{}}}
\bibcite{balkenius1991nonmonotonic}{{3}{1991}{{Balkenius and G{\"a}rdenfors}}{{}}}
\bibcite{baltag2019dynamic}{{4}{2019{a}}{{Baltag et~al.}}{{Baltag, Gierasimczuk, {\"O}zg{\"u}n, Sandoval, and Smets}}}
\bibcite{baltag2019right}{{5}{2019{b}}{{Baltag et~al.}}{{Baltag, Li, and Pedersen}}}
\bibcite{blutner2004nonmonotonic}{{6}{2004}{{Blutner}}{{}}}
\bibcite{garcez2008neural}{{7}{2008}{{Garcez et~al.}}{{Garcez, Lamb, and Gabbay}}}
\bibcite{garcez2001symbolic}{{8}{2001}{{Garcez et~al.}}{{Garcez, Broda, and Gabbay}}}
\bibcite{giordano2021}{{9}{2021}{{Giordano et~al.}}{{Giordano, Gliozzi, and Dupr{\'{e}}}}}
\bibcite{hebb-organization-of-behavior-1949}{{10}{1949}{{Hebb}}{{}}}
\bibcite{kisby2022logic}{{11}{2022}{{Kisby et~al.}}{{Kisby, Blanco, and Moss}}}
\bibcite{kraus1990nonmonotonic}{{12}{1990}{{Kraus et~al.}}{{Kraus, Lehmann, and Magidor}}}
\bibcite{leitgeb2001nonmonotonic}{{13}{2001}{{Leitgeb}}{{}}}
\bibcite{leitgeb2003nonmonotonic}{{14}{2003}{{Leitgeb}}{{}}}
\bibcite{leitgeb2018neural}{{15}{2018}{{Leitgeb}}{{}}}
\bibcite{mcculloch1943logical}{{16}{1943}{{McCulloch and Pitts}}{{}}}
\@writefile{toc}{\contentsline {section}{Acknowledgements}{10}{section*.15}\protected@file@percent }
\bibcite{sarker2021neuro}{{17}{2021}{{Sarker et~al.}}{{Sarker, Zhou, Eberhart, and Hitzler}}}
\bibcite{valiant2003three}{{18}{2003}{{Valiant}}{{}}}
\bibcite{van2007beliefrevision}{{19}{2007}{{Van~Benthem}}{{}}}
\bibcite{van2007prefupgrade}{{20}{2007}{{Van~Benthem and Liu}}{{}}}
\gdef \@abspage@last{11}
