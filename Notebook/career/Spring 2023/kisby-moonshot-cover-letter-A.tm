<TeXmacs|2.1.1>

<style|<tuple|letter|pagella-font|compact-list>>

<\body>
  <\hide-preamble>
    \;

    <assign|signature|<macro|body|<surround|<vspace*|5fn><left-flush>||<signature*|<arg|body>>>>>

    <assign|closing|<macro|body|<surround|<left-flush>||<signature*|<arg|body>>>>>

    <assign|doc-misc|<macro|body|<doc-title-block|<arg|body>>>>

    <assign|doc-title|<macro|x|<\surround|<vspace*|0.5fn>|<vspace*|0.5fn>>
      <doc-title-block|<font-magnify|1.682|<doc-title-name|<arg|x>>>>
    </surround>>>

    <assign|doc-title-name|<macro|x|<arg|x>>>
  </hide-preamble>

  <doc-data|<doc-title|Caleb Schultz Kisby>|<\doc-misc>
    <with|font-series|bold|Email:> <hlink|cckisby@iu.edu|mailto:cckisby@iu.edu><space|2em><with|font-series|bold|Phone:>
    +1 609 455 0673<new-line>\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V
  </doc-misc>|<with|doc-misc|<macro|body|<vspace*|0.5fn><doc-title-block|<arg|body>><vspace|0.5fn>>|<\doc-misc>
    jlk;dffjas;lfd

    \V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V\V
  </doc-misc>>>

  <with|font-series|bold|Position:> PhD Residency - AI/ML - LLMs, NLP,
  Abstraction, Reasoning

  \;

  <\opening>
    Dear X hiring team,
  </opening>

  Hi, I'm Caleb, a 5<math|<rsup|th>> year PhD candidate at Indiana
  University. I specialize in integrating neural networks and symbolic
  reasoning (aka neuro-symbolic AI), and I'm excited to see that you are
  looking for a PhD Resident to do just that. This seems like a great fit,
  and so I'm here to apply.

  I have 6 years of experience (4 PhD + 2 undergrad) working on fast
  prototypes in different research environments. I've published and presented
  3 papers in AI conferences (one in AAAI!). My work synthesizes machine
  learning (neural networks, reinforcement learning) with formal reasoning
  (logic, formal verification, interpreters). Every neural network
  architecture I've designed incorporates symbolic reasoning in some way \V
  see the open-source projects listed on my resume. Most recently, I've been
  developing a suite (in Python, via Tensorflow) to both
  <with|font-shape|italic|verify> if a neural network satisfies <math|P> and
  to <with|font-shape|italic|build> neural networks satisfying <math|P> (this
  uses a neuro-symbolic translation that I've proved is formally sound).

  This also means that, unlike most machine learning researchers, I have a
  particularly strong background in formal logic and programming language
  theory. I've written interpreters for custom languages, worked in type-rich
  and functional languages (e.g. Agda, Lean, Lisp, and Haskell), and I've
  proved systems formally sound and complete.

  As for NLP: I've always had natural language in mind as the perfect domain
  for combining learning and reasoning. I've taken graduate courses on
  classical (compositional) semantics, as well as distributional (vector)
  semantics. I have also used the NLTK and Word2Vec Python packages in
  independent projects for these classes. And although I don't yet have
  experience with Large Language Models (LLMs), I do have a strong interest
  in working with transformers. (In fact, I'm currently thinking through how
  to extend my formally sound neuro-symbolic translation to deal with
  attention!)

  If you are interested, I'm available for a phone or Zoom interview during
  normal business hours (8am\U6pm, EST) \V please email me at the address
  above to schedule a time.

  <\closing>
    Thank you for your consideration,
  </closing>

  <\signature>
    Caleb Schultz Kisby
  </signature>
</body>

<\initial>
  <\collection>
    <associate|font-base-size|12>
    <associate|math-font|math-pagella>
    <associate|page-even-footer|<htab|5mm><htab|5mm>>
    <associate|page-even-header|>
    <associate|page-height|auto>
    <associate|page-medium|paper>
    <associate|page-odd-footer|<htab|5mm><htab|5mm>>
    <associate|page-odd-header|>
    <associate|page-screen-margin|false>
    <associate|page-type|letter>
    <associate|page-width|auto>
  </collection>
</initial>