<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:x="https://www.texmacs.org/2002/extensions" xmlns:m="http://www.w3.org/1998/Math/MathML">
  <head>
    <title>Massimiliano Gubinelli</title>
    <meta content="TeXmacs 2.1.2" name="generator"></meta>
    <link href="/resources/notes-base.css" type="text/css" rel="stylesheet"></link>
    <link href="/resources/favicon-32x32.png" rel="icon"></link>
    <script src="/resources/highlight.pack.js" language="javascript" defer></script>
    <script src="/resources/notes-base.js" language="javascript" defer></script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" language="javascript"></script>
  </head>
  <body>
    <div class="toggle" style="display: none">
      <p>
        
      </p>
    </div>
    <div class="notes-header">
      <p>
        [<a href="../main.html">main</a>] [<a href="./teaching.html">teaching</a>]<em class="notes-header-name">mg|pages</em>
      </p>
    </div>
    <h1 id="auto-1">Enseignements 2010/2011<span style="margin-left: 1em"></span></h1>
    <div class="notes-abstract">
      Lectures delivered at Paris Dauphine, academic year 2010&ndash;2011.
    </div>
    <p>
      <b>Ann&eacute;e 2010/2011</b>
    </p>
    <ul>
      <li>
        <p>
          <a href="#bf">Analyse des fonctions bool&eacute;ennes (M2 EDPMAD/TSI)</a>
        </p>
      </li>
      <li>
        <p>
          <a href="#pd">Processus discrets (M1 MMD)</a>
        </p>
      </li>
      <li>
        <p>
          <a href="#ccm">Contr&ocirc;le des cha&icirc;nes de Markov (M1 MMD)</a>
        </p>
      </li>
      <li>
        <p>
          <a href="#stat">Statistique (DU2 Eco IGD Math/Eco Mat/Info)</a>
        </p>
      </li>
    </ul>
    <h4 id="bf"><a id="auto-2"></a>Analysis of Boolean functions [Analyse des fonctions
    bool&eacute;ennes] (M2 EDPMAD/TSI)<span style="margin-left: 1em"></span></h4>
    <p>
      <b>Descriptive du cours</b>
    </p>
    <p>
      Une fonction bool&eacute;enne est une fonction \(f : \{- 1, 1\}^n
      \rightarrow \{- 1, 1\}\). Les fonction bool&eacute;ennes apparaissent
      souvent dans des situations vari&eacute;es: en math&eacute;matiques
      (th&eacute;orie des graphes, percolation), en informatique
      th&eacute;orique (algorithmes de classification, th&eacute;orie de la
      complexit&eacute; algorithmique, optimisation combinatoire), sciences
      sociales et &eacute;conomie (choix sociale, syst&egrave;mes de vote). Ce
      cours est une introduction &agrave; l'analyse de ce type de fonctions et
      aux r&eacute;sultats (parfois &eacute;tonnants) qui en r&eacute;sultent.
      On donnera des applications &agrave; la th&eacute;orie du choix sociale:
      quelles sont les propri&eacute;t&eacute;s des syst&egrave;mes de vote,
      le paradoxe de Condorcet, le th&eacute;or&egrave;me de Arrow, le
      th&eacute;or&egrave;me de Kahn-Kalai-Linial, la sensibilit&eacute; au
      bruit et les ph&eacute;nom&egrave;nes de &ldquo;chaos&quot;.
    </p>
    <p>
      <b>Mots clefs:</b> analyse de Fourier des fonctions bool&eacute;ennes,
      sensibilit&eacute; aux bruit, ph&eacute;nom&egrave;nes de seuil,
      influence, hypercontractivit&eacute;, criticalit&eacute;
      auto-organis&eacute;e, paradoxe de Condorcet, th&eacute;or&egrave;me de
      Arrow, agr&eacute;gation de l'information.
    </p>
    <p>
      <b>Bibliographie et liens (en anglais)</b>
    </p>
    <ul>
      <li>
        <p>
          Paradoxe de Condorcet (<a href="http://fr.wikipedia.org/wiki/Paradoxe_de_Condorcet">wp</a>), Th&eacute;or&egrave;me de
          Arrow (<a href="http://fr.wikipedia.org/wiki/Th&Atilde;&#x013E;or&Atilde;&#x013A;me_d%27impossibilit&Atilde;&#x013E;_d%27Arrow">wp</a>), Th&eacute;orie du choix sociale (<a href="http://en.wikipedia.org/wiki/Social_choice_theory">wp</a>)
        </p>
      </li>
      <li>
        <p>
          Le cours of O'Donnell sur l'analyse des fonctions bool&eacute;ennes
          (<a href="http://www.cs.cmu.edu/~odonnell/boolean-analysis/">link</a>)
        </p>
      </li>
      <li>
        <p>
          Le cours de Kalai sur la th&eacute;orie du choix sociale (<a href="http://www.ma.huji.ac.il/~kalai/course07.html">link</a>)
        </p>
      </li>
      <li>
        <p>
          Le cours de E. Friedgut sur les m&eacute;thodes analytiques en
          combinatoire et informatique (<a href="http://www.cs.huji.ac.il/~analyt/">link</a>)
        </p>
      </li>
      <li>
        <p>
          Le cours de N. Linian sur l'analise harmonique et ses applications
          combinatoires (<a href="http://www.cs.huji.ac.il/~nati/PAPERS/uw/">link</a>)
        </p>
      </li>
      <li>
        <p>
          Page web de Gil Kalai (<a href="http://www.ma.huji.ac.il/~kalai">link</a>)
        </p>
      </li>
      <li>
        <p>
          G. Kalai and S. Safra. Threshold Phenomena and Influence, in:
          Computational Complexity and Statistical Physics, A.G. Percus, G.
          Istrate and C. Moore, eds. (Oxford University Press, New York,
          2006), pp. 25-60. (<a href="../../store/e1011/http://www.ma.huji.ac.il/~kalai/ML.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          G. Kalai, A Fourier-Theoretic Perspective for the Condorcet Paradox
          and Arrow's theorem, Adv. in Appl. Math. 29(2002), 412-426. (<a
          href="../../store/e1011/http://www.ma.huji.ac.il/~kalai/arr.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          G. Kalai, Social Indeterminacy, Econometrica, 72 (2004), 1565-1581.
          (<a href="../../store/e1011/http://www.ma.huji.ac.il/~kalai/SI.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          G. Kalai, Noise sensitivity and chaos in social choice theory.
          Discussion Paper Series dp399, Center for Rationality and
          Interactive Decision Theory, Hebrew University, Jerusalem. (<a href="../../store/e1011/http://www.ma.huji.ac.il/~kalai/CHAOS.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          O'Donnell, R. 2008. Some topics in analysis of boolean functions. In
          Proceedings of the 40th Annual ACM Symposium on theory of Computing
          (Victoria, British Columbia, Canada, May 17 - 20, 2008). STOC '08.
          ACM, New York, NY, 569-578. (<a href="http://doi.acm.org/10.1145/1374376.1374458">doi</a>) (<a href="../../store/e1011/http://www.cs.cmu.edu/~odonnell/papers/analysis-survey.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          E. Friedgut, G. Kalai, N. Nisan, Elections Can be Manipulated Often
          (<a href="../../store/e1011/http://www.ratio.huji.ac.il/dp_files/dp481.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          &quot;Hypercontractivity and its applications&quot;, a survey by
          Punya Biswal (<a href="../../store/e1011/http://cdn.bitbucket.org/punya/hypercontractivity-survey/downloads/Quals.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          TCS math blog (<a href="http://tcsmath.wordpress.com/">link</a>)
        </p>
      </li>
      <li>
        <p>
          The program &ldquo;Metric geometry, algoritms and groups&rdquo; at
          IHP (Jan-April 2011) (<a href="http://www.math.ens.fr/metric2011/">link</a>)
        </p>
      </li>
    </ul>
    <p>
      <b>Journal</b>
    </p>
    <ol>
      <li>
        <p>
          [6/1, 10h00-13h15, A301] Not held.
        </p>
      </li>
      <li>
        <p>
          [13/1, 10h00-13h15, B212] Not held.
        </p>
      </li>
      <li>
        <p>
          [20/1, 10h00-13h15, B104 bis] Introduction. Social choice theory
          motivations. Fourier analysis.
        </p>
      </li>
      <li>
        <p>
          [27/1, 10h00-13h15, B104 bis] BLR test, Friedgut-Kalai-Naor theorem
          and Kalai's robust version of Arrow's theorem.
        </p>
      </li>
      <li>
        <p>
          [3/2, 13h45-17h00, B203] A first look at hypercontractivity. Some
          properties of the majority function. The noise operator and
          stability of the majority function.
        </p>
      </li>
      <li>
        <p>
          [10/2, 13h45-17h00, B203] A proof of the general hypercontractivity
          inequality. Influences. The Tribes function and the KKL theorem.
        </p>
      </li>
      <li>
        <p>
          [5/4, 13h45-17h00, A305] Proof of the KKL theorem and Friedgut
          theorem.
        </p>
      </li>
      <li>
        <p>
          [6/4, 9h00-12h00, A305] Influences of coalitions. Noise sensitivity
          and Social chaos.
        </p>
      </li>
    </ol>
    <p>
      <b>Course material (in english)</b>
    </p>
    <ol>
      <li>
        <p>
          Lecture 1. Introduction. Social choice theory. Fourier analysis. BLR
          ad FKN theorems. (<a href="../../store/e1011/abf1.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          Lecture 2. Hypercontractivity. A first look to majority. Influences.
          KKL and Friedgut theorems. Influential coalitions. (<a href="../../store/e1011/abf2.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          Lecture 3. Noise sensitivity and social chaos. (<a href="../../store/e1011/abf3.pdf">PDF</a>)
        </p>
      </li>
    </ol>
    <h4 id="pd"><a id="auto-3"></a>Processus discrets (M1 MMD)<span style="margin-left: 1em"></span></h4>
    <ul>
      <li>
        <p>
          Cours de l'ann&eacute;e derni&egrave;re (<a href="teaching-dauphine-09-10.html#pd">Lien</a>)
        </p>
      </li>
      <li>
        <p>
          Charg&eacute;s de TD: Joseph Lehec et Fran&ccedil;ois Simenhaus.
        </p>
      </li>
    </ul>
    <p>
      <b>Programme</b>
    </p>
    <ol>
      <li>
        <p>
          Esp&eacute;rance conditionnelle.
        </p>
      </li>
      <li>
        <p>
          Martingales. Strat&eacute;gies. Convergence des martingales.
          Arr&ecirc;t optionnel.
        </p>
      </li>
      <li>
        <p>
          Cha&icirc;nes de Markov.
        </p>
      </li>
    </ol>
    <p>
      <b>Bibliographie conseill&eacute;e</b>
    </p>
    <ul>
      <li>
        <p>
          D. Williams, <em> Probability with martingales </em>, Cambridge.
        </p>
      </li>
      <li>
        <p>
          P.Bremaud, <em>Introduction aux probabilit&eacute;s.
          Mod&eacute;lisation des ph&eacute;nom&egrave;nes
          al&eacute;atoires</em>, Springer-verlag, New-York, 1984.
        </p>
      </li>
      <li>
        <p>
          M. Bena&iuml;m, N. El Karoui. <em> Promenade ale&eacute;atoire</em>,
          Editions Ecole Polytechnique, 2005.
        </p>
      </li>
      <li>
        <p>
          J.R.Norris. <em> Markov chains</em>, Cambridge University Press,
          1997
        </p>
      </li>
      <li>
        <p>
          P. Baldi, L. Mazliak, P. Priouret, <em> Martingales et cha&icirc;nes
          de Markov (Exercices corrig&eacute;s) </em>, Hermann
        </p>
      </li>
      <li>
        <p>
          J.Neveu. <em> Martingales &agrave; temps discret</em>, Masson,
          Paris, 1972
        </p>
      </li>
      <li>
        <p>
          R.Durrett. <em> Probability: Theory and Examples</em>, Wadsworth and
          Brooks, Pacific Grove, 1991
        </p>
      </li>
      <li>
        <p>
          M.Cottrel, Ch.Duhamel, V.Genon-Catalot. <em> Exercices de
          Probabilit&eacute;s</em>, Berlin, Paris, 1980
        </p>
      </li>
      <li>
        <p>
          Le cours de Lalley (<a href="http://galton.uchicago.edu/~lalley/Courses/313/">link</a>)
        </p>
      </li>
    </ul>
    <p>
      <b>Journal</b>
    </p>
    <ol>
      <li>
        <p>
          [21/9, 8h30, Amphi 6] Introduction du cours. Pr&eacute;-requis.
          Sous-tribus. Motivation et d&eacute;finition g&eacute;n&eacute;rale
          de l'esp&eacute;rance conditionnelle.
        </p>
      </li>
      <li>
        <p>
          [28/9, 8h30, Amphi 6] Preuve de l'unicit&eacute; p.s. de
          l'esp&eacute;rance conditionnelle. Quelques propri&eacute;t&eacute;s
          des l'esp&eacute;rance conditionnelle.
        </p>
      </li>
      <li>
        <p>
          [5/10, 8h30, Amphi 6] Martingales et leur lien avec les
          strat&eacute;gies dans les jeux d'hasard.
        </p>
      </li>
      <li>
        <p>
          [12/10, 8h30, Amphi 6] D&eacute;finition et caract&eacute;risation
          des martingales, premi&egrave;res propri&eacute;t&eacute;s,
          transformation de martingale, processus pr&eacute;visibles,
          stabilit&eacute; de la notion de martingale par rapport aux
          transformation avec les processus pr&eacute;visibles.
        </p>
      </li>
      <li>
        <p>
          [19/10, 8h30, Amphi 6] Processus arr&ecirc;t&eacute;.
          Th&eacute;or&egrave;me d'arr&ecirc;t optionnel de Doob. Introduction
          aux ph&eacute;nom&egrave;nes de convergence des martingales.
        </p>
      </li>
      <li>
        <p>
          [26/10, 8h30, Amphi 6] Travers&eacute;es montantes,
          th&eacute;or&egrave;me de convergence des martingales.
        </p>
      </li>
      <li>
        <p>
          [2/11, 8h30, Amphi 6] Convergence en moyenne quadratique des
          martingales born&eacute;es en L&sup2;.
        </p>
      </li>
      <li>
        <p>
          [9/11, 8h30, Amphi 6] Cha&icirc;nes de Markov. Matrice de
          transition. Equation de Chapman-Kolmogorov.
        </p>
      </li>
      <li>
        <p>
          [23/11, 8h30, Amphi 6] Construction d'une cha&icirc;ne avec matrice
          de transition donn&eacute;e.
        </p>
      </li>
      <li>
        <p>
          [30/11, 8h30, Amphi 6] Classification des &eacute;tats.
          R&eacute;currence.
        </p>
      </li>
      <li>
        <p>
          [7/12, 8h30, Amphi 6] Crit&egrave;res pour la r&eacute;currence et
          la transience.
        </p>
      </li>
      <li>
        <p>
          [14/12, 8h30, Amphi 6] Probabilit&eacute;s invariantes. Existence.
        </p>
      </li>
      <li>
        <p>
          [4/1, 8h30, Amphi 6] Unicit&eacute; dans le cas irr&eacute;ductible.
          Excursions. R&eacute;currence positive. Lien entre
          probabilit&eacute; invariante et temps moyens de retour.
          Th&eacute;or&egrave;me ergodique et convergence &agrave;
          l'&eacute;quilibre.
        </p>
      </li>
    </ol>
    <p>
      <b>Notes de cours et TDs</b>
    </p>
    <ol>
      <li>
        <p>
          Poly 1. Esp&eacute;rance conditionnelle (<a href="../../store/e1011/pd1.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          Poly 2. Martingales, strat&eacute;gies et arr&ecirc;t optionnel (<a
          href="../../store/e1011/pd2.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          Poly 3. Comportement asymptotique des martingales (<a href="../../store/e1011/pd3.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          Poly 4. Cha&icirc;nes de Markov (<a href="../../store/e1011/pd4.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          TD1. Esp&eacute;rance conditionnelle. (<a href="../../store/e1011/pd-td1.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          TD2. Martingales, strat&eacute;gies et arr&ecirc;t optionnel (<a
          href="../../store/e1011/pd-td2.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          TD3. Comportement asymptotique des martingales (<a href="../../store/e1011/pd-td3.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          TD4. Cha&icirc;nes de Markov (<a href="../../store/e1011/pd-td4.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          TD5. Cha&icirc;nes de Markov (II) (<a href="../../store/e1011/pd-td5.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          Partiel (<a href="../../store/e1011/pd-partiel-1011.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          Corrig&eacute; Partiel (<a href="../../store/e1011/pd-partiel-1011-corrige.pdf">PDF</a>)
        </p>
      </li>
    </ol>
    <p>
      <b>Sujets des ann&eacute;es pr&eacute;c&eacute;dentes</b>
    </p>
    <ol>
      <li>
        <p>
          2004/2004. Examen (<a href="../../store/e1011/md-controle2004.pdf">PDF</a>). Rattrapage (<a href="../../store/e1011/md-controle-sett2005.pdf">PDF</a>).
        </p>
      </li>
      <li>
        <p>
          2005/2006. Examen (<a href="../../store/e1011/proc-controle0106.pdf">PDF</a>). Rattrapage (<a href="../../store/e1011/proc-controle0906Rectif.pdf">PDF</a>).
        </p>
      </li>
      <li>
        <p>
          2006/2007. Partiel (<a href="../../store/e1011/PartielProcDiscrets0607.pdf">PDF</a>). Examen (<a href="../../store/e1011/proc-controle0107.pdf">PDF</a>).
          Rattrapage (<a href="../../store/e1011/proc-controle0907.pdf">PDF</a>).
        </p>
      </li>
      <li>
        <p>
          2007/2008. Partiel (<a href="../../store/e1011/PartielProcDiscrets0708.pdf">PDF</a>). Examen (<a href="../../store/e1011/proc-controle0108.pdf">PDF</a>).
          Rattrapage (<a href="../../store/e1011/proc-controle0908.pdf">PDF</a>).
        </p>
      </li>
      <li>
        <p>
          2008/2009. Examen (<a href="../../store/e1011/proc-controle0109.pdf">PDF</a>).
        </p>
      </li>
      <li>
        <p>
          2009/2010. Partiel (<a href="../../store/e1011/pd-partiel-0910.pdf">PDF</a>). Corrig&eacute; Partiel (<a
          href="../../store/e1011/pd-partiel-corrige-0910.pdf">PDF</a>). Examen (<a href="../../store/e1011/pd-examen-0910.pdf">PDF</a>). Rattrapage (<a href="../../store/e1011/pd-rattrapage-0910.pdf">PDF</a>).
        </p>
      </li>
    </ol>
    <h4 id="ccm"><a id="auto-4"></a>Contr&ocirc;le des chaines de Markov (M1 MMD - parcours
    MAMD)<span style="margin-left: 1em"></span></h4>
    <ul>
      <li>
        <p>
          Cours de l'ann&eacute;e derni&egrave;re (<a href="teaching-dauphine-09-10.html#ccm">Lien</a>)
        </p>
      </li>
      <li>
        <p>
          Charg&eacute; de TD: Jimmy Lamboley.
        </p>
      </li>
    </ul>
    <p>
      <b>Programme</b>
    </p>
    <ol>
      <li>
        <p>
          Compl&eacute;ments sur l'esp&eacute;rance conditionnelle.
        </p>
      </li>
      <li>
        <p>
          Cha&icirc;nes de Markov contr&ocirc;l&eacute;es.
        </p>
      </li>
      <li>
        <p>
          Compl&eacute;ments sur les temps d'arr&ecirc;t et sur les
          martingales. Arr&ecirc;t optimal en horizon fini. Enveloppe de Snell
        </p>
      </li>
      <li>
        <p>
          Arr&ecirc;t optimale en horizon infini. Principe
          d'optimalit&eacute;. Exemples et applications.
        </p>
      </li>
    </ol>
    <p>
      <b>Bibliographie conseill&eacute;e (en anglais)</b>
    </p>
    <ul>
      <li>
        <p>
          Les notes de cours de James Norris &agrave; Cambridge (<a href="http://www.statslab.cam.ac.uk/~james/Lectures/old.html&#x02D9;">url</a>)
        </p>
      </li>
      <li>
        <p>
          Le cours de Ben Van Roy &agrave; Stanford (<a href="http://erdos.stanford.edu/ee292/">url</a>)
        </p>
      </li>
      <li>
        <p>
          Bertsekas, D. P.,<em> Dynamic Programming</em>. Prentice Hall, 1987.
        </p>
      </li>
      <li>
        <p>
          Bertsekas, D. P., <em>Dynamic Programming and Optimal Control</em>,
          Volumes I and II, Prentice Hall, 1995.
        </p>
      </li>
      <li>
        <p>
          Hocking, L. M., <em>Optimal Control: An introduction to the theory
          and applications</em>, Oxford 1991.
        </p>
      </li>
      <li>
        <p>
          Ross, S., <em>Introduction to Stochastic Dynamic Programming</em>.
          Academic Press, 1983.
        </p>
      </li>
    </ul>
    <p>
      <b>Journal</b>
    </p>
    <ol>
      <li>
        <p>
          [23/9, 15h30, A307] Rappels sur l'espace L&sup2; et
          compl&eacute;ments sur l'esp&eacute;rance conditionnelle.
        </p>
      </li>
      <li>
        <p>
          [30/9, 15h30, A307]Existence de l'esp&eacute;rance conditionnelle.
          Preuve de quelques propri&eacute;t&eacute;s.
        </p>
      </li>
      <li>
        <p>
          [7/10, 15h30, A307] Arr&ecirc;t optimal en horizon fini. Lien avec
          les martingales. Enveloppe de Snell.
        </p>
      </li>
      <li>
        <p>
          [14/10, 15h30, A307] Preuve du th&eacute;or&egrave;me d'arr&ecirc;t
          optimal et compl&eacute;ments.
        </p>
      </li>
      <li>
        <p>
          [21/10, 15h30, A307] Etude des temps d'arr&ecirc;t optimaux.
        </p>
      </li>
      <li>
        <p>
          [28/10, 17h00, A307] Integrabilit&eacute; uniforme.
        </p>
      </li>
      <li>
        <p>
          [4/11, 15h30, A307] Martingales uniform&eacute;ment
          int&eacute;grables.
        </p>
      </li>
      <li>
        <p>
          [11/11, 15h30, A307] Martingales r&eacute;trogrades. Loi du 0-1 de
          L&eacute;vy, de Kolmogorov et d&eacute;monstration de la loi forte
          des grandes nombres.
        </p>
      </li>
      <li>
        <p>
          [25/11, 15h30, A307] Cha&icirc;nes de Markov
          contr&ocirc;l&eacute;es.
        </p>
      </li>
      <li>
        <p>
          [2/12, 15h30, A307] R&eacute;currence al&eacute;atoires
          contr&ocirc;l&eacute;es. Cas homog&egrave;ne en temps. Equation de
          Bellman.
        </p>
      </li>
      <li>
        <p>
          [9/12, 15h30, A307] Contr&ocirc;le en horizon fini.
        </p>
      </li>
      <li>
        <p>
          [16/12, 15h30, A307] Contr&ocirc;le en horizon infini. Cas de gains
          positifs.
        </p>
      </li>
      <li>
        <p>
          [6/1, 15h30, A307]
        </p>
      </li>
      <li>
        <p>
          [16/1, 15h30, A307]
        </p>
      </li>
    </ol>
    <p>
      <b>Notes de cours et TDs</b>
    </p>
    <ol>
      <li>
        <p>
          Poly 1. Compl&eacute;ments sur l'esp&eacute;rance conditionnelle (<a
          href="../../store/e1011/ccm1.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          Poly 2. Arr&ecirc;t optimal en horizon fini. (<a href="../../store/e1011/ccm2.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          Poly 4. Cha&icirc;nes de Markov contr&ocirc;l&eacute;es. (<a href="../../store/e1011/ccm4.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          TD1. Compl&eacute;ments sur l'esp&eacute;rance conditionnelle. (<a
          href="../../store/e1011/ccm-td1.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          TD2. Arr&ecirc;t optimal en horizon fini. (<a href="../../store/e1011/ccm-td2.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          TD3. Integrabilit&eacute; uniforme. (<a href="../../store/e1011/ccm-td3.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          TD4. Cha&icirc;nes de Markov contr&ocirc;l&eacute;es. (<a href="../../store/e1011/ccm-td4.pdf">PDF</a>)
        </p>
      </li>
    </ol>
    <p>
      <b>Sujets des ann&eacute;es pr&eacute;c&eacute;dentes</b>
    </p>
    <ol>
      <li>
        <p>
          2008/2009. Examen (<a href="../../store/e1011/examen-control-chaines-2009.pdf">PDF</a>). Rattrapage (<a href="../../store/e1011/rattrapage-control-chaines-2009.pdf">PDF</a>).
        </p>
      </li>
      <li>
        <p>
          2009/2010. Partiel (<a href="../../store/e1011/ccm-partiel-0910.pdf">PDF</a>). Corrig&eacute; Partiel (<a
          href="../../store/e1011/ccm-partiel-corrige-0910.pdf">PDF</a>). Examen (<a href="../../store/e1011/ccm-examen-0910.pdf">PDF</a>). Rattrapage (<a href="../../store/e1011/ccm-rattrapage-0910.pdf">PDF</a>).
        </p>
      </li>
    </ol>
    <h4 id="stat"><a id="auto-5"></a>Statistique (DU2 Eco IGD Math/Eco Mat/Info)<span style="margin-left: 1em"></span></h4>
    <ul>
      <li>
        <p>
          Cours de l'ann&eacute;e derni&egrave;re (<a href="teaching-dauphine-09-10.html#stat">Lien</a>)
        </p>
      </li>
      <li>
        <p>
          Charg&eacute;s de TD: Anne-Marie Boussion (TD1). Massimiliano
          Gubinelli (TD2) Vincent Rivoirard (TD3). Denis Pasquignon (TD4).
          Benjamin Benoudis (TD5). Olga Tchebotareva (TD6).
        </p>
      </li>
    </ul>
    <p>
      <b>Programme</b>
    </p>
    <ol>
      <li>
        <p>
          Rappels s&ucirc;r les int&eacute;grales multiples et le
          distributions des vecteurs al&eacute;atoires.
        </p>
      </li>
      <li>
        <p>
          Vecteurs al&eacute;atoires gaussiens. Lois Gamma, Beta, Khi-deux,
          Student.
        </p>
      </li>
      <li>
        <p>
          Convergence et th&eacute;or&egrave;mes limites.
          In&eacute;galit&eacute;s de Tchebichev et H&ouml;lder. Convergence
          en loi. Convergence en probabilit&eacute;. loi faible des grands
          nombres. Convergence presque s&ucirc;re. Loi forte des grands
          nombres. Convergence en moyenne p-eme. Th&eacute;or&egrave;me
          Central Limite. La delta-m&eacute;thode.
        </p>
      </li>
      <li>
        <p>
          Estimation ponctuelle. Mod&egrave;le param&eacute;trique.
          Estimateurs ponctuels. Exhaustivit&eacute; des statistiques.
          M&eacute;thodes d'estimation: moments, maximum de vraisemblance.
        </p>
      </li>
      <li>
        <p>
          Estimation par intervalles de confiance.
        </p>
      </li>
      <li>
        <p>
          Test d'hypoth&egrave;ses. Test du rapport de vraisemblances. Test du
          Khi-deux. Test d'ind&eacute;pendance.
        </p>
      </li>
    </ol>
    <p>
      <b>Journal</b>
    </p>
    <ol>
      <li>
        <p>
          [4/2, 8h30, Amphi 1] Introduction au cours. Vecteurs
          al&eacute;atoires avec densit&eacute;. Densit&eacute;s marginales et
          densit&eacute; conditionnelle.
        </p>
      </li>
      <li>
        <p>
          [11/2, 8h30, Amphi 1] Ind&eacute;pendance des vecteurs
          al&eacute;atoires. Esp&eacute;rance. Esp&eacute;rance conditionnelle
          et ses propri&eacute;t&eacute;s. Covariance et coefficient de
          corr&eacute;lation.
        </p>
      </li>
      <li>
        <p>
          [16/2, 12h00, Amphi 1] Propri&eacute;t&eacute;s de la covariance.
          Variance conditionnelle. Formule de la variance conditionnelle.
          Matrice de covariance d'un vecteur al&eacute;atoire et ses
          propri&eacute;t&eacute;s.
        </p>
      </li>
      <li>
        <p>
          [18/2, 8h30, Amphi 1] Fonction caract&eacute;ristique pour une v.a.
          et un vecteur al&eacute;atoire. Exemples. Vecteurs al&eacute;atoires
          gaussiens. Premi&egrave;res propri&eacute;t&eacute;s.
        </p>
      </li>
      <li>
        <p>
          [2/3, 12h00, Amphi 1] Caract&eacute;risation des vecteurs gaussiens.
          Vecteurs gaussiens avec moyenne et variance donn&eacute;es.
        </p>
      </li>
      <li>
        <p>
          [4/3, 8h30, Amphi 1] Fonction caract&eacute;ristique d'un vecteur
          gaussien. D&eacute;finition de la loi gaussienne multidimensionnelle
          avec moyenne et variance donn&eacute;e. Densit&eacute; d'un vecteur
          avec matrice de covariance inversible.
        </p>
      </li>
      <li>
        <p>
          [9/3, 12h00, Amphi 1] Lien entre covariance et ind&eacute;pendance
          pour les vecteurs gaussiens. Introduction &agrave; la convergence
          des variables al&eacute;atoires. Exemple de convergence (en loi)
          d'une suite de v.a. vers une v.a. uniforme. Th&eacute;or&egrave;me
          sur la convergence jointe des fonction caract&eacute;ristiques, des
          moyennes et des fonctions de r&eacute;partitions. D&eacute;finition
          de convergence en loi.
        </p>
      </li>
      <li>
        <p>
          [18/3, 8h30, Amphi 1] Convergence en probabilit&eacute;.
          In&eacute;galit&eacute; de Markov et Tchebychev. Loi faible des
          grandes nombres. Convergence presque s&ucirc;re. Loi forte des
          grandes nombres. Th&eacute;or&egrave;me Centrale Limite.
        </p>
      </li>
      <li>
        <p>
          [27/4, 12h00, Amphi 1] Convergence en moyenne r-&eacute;me.
          In&eacute;galit&eacute; de Jensen. Convergence de la moyenne. Lien
          entre les modes de convergence. Th&eacute;or&egrave;me de
          continuit&eacute;. Lemme de Slusky.
        </p>
      </li>
      <li>
        <p>
          [3/5, 17h15, Amphi 4]
        </p>
      </li>
      <li>
        <p>
          [11/5, 12h00, Amphi 1]
        </p>
      </li>
      <li>
        <p>
          [17/5, 17h15, Amphi 4?]
        </p>
      </li>
      <li>
        <p>
          [18/5, 12h00, Amphi 1]
        </p>
      </li>
    </ol>
    <p>
      <b>Cours</b>
    </p>
    <ol>
      <li>
        <p>
          Poly 1. Vecteurs al&eacute;atoires, esp&eacute;rance conditionnelle,
          r&eacute;gression. (<a href="../../store/e1011/stat1.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          Poly 2. Matrice de covariance. Fonction caract&eacute;ristique.
          Vecteurs Gaussiens. (<a href="../../store/e1011/stat2.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          Poly 3. Convergence des variables al&eacute;atoires. Loi des grandes
          nombres et th&eacute;or&egrave;me centrale limite. (<a href="../../store/e1011/stat3.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          Poly 4. Estimation ponctuelle. (<a href="../../store/e1011/stat4.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          Poly 5. Intervalles de confiance. (<a href="../../store/e1011/stat5.pdf">PDF</a>)
        </p>
      </li>
    </ol>
    <p>
      <b>Feuilles de TD et sujets</b>
    </p>
    <ol>
      <li>
        <p>
          TD1: Int&eacute;grales doubles et couples de variables
          al&eacute;atoires. (<a href="../../store/e1011/stat-td1.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          TD2: Vecteurs al&eacute;atoires, vecteurs Gaussiens et loi Gamma et
          Khi-deux. (<a href="../../store/e1011/stat-td2.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          TD3: Vecteurs Gaussiens. (<a href="../../store/e1011/stat-td3.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          TD4: Convergence en loi. (<a href="../../store/e1011/stat-td4.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          TD5: Estimation ponctuelle. (<a href="../../store/e1011/stat-td5.pdf">PDF</a>)
        </p>
      </li>
      <li>
        <p>
          TD6: Intervalles de confiance. (<a href="../../store/e1011/stat-td6.pdf">PDF</a>)
        </p>
      </li>
    </ol>
  </body>
</html>